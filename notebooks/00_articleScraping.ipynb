{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/raw/ISOTFakeNewsDataset/True.csv\")\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a040a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../data/raw/ISOTFakeNewsDataset/Fake.csv\")\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# === CONFIG ===\n",
    "INPUT_FILE = \"../data/raw/FakeNewsNet/gossipcop_fake.csv\"\n",
    "OUTPUT_FILE = \"../data/processed/gossipcop_sample.csv\"\n",
    "NUM_ARTICLES = 500\n",
    "MAX_WORKERS = 16   # tune based on CPU / network\n",
    "TIMEOUT = 10    # max seconds to wait per article\n",
    "\n",
    "# === Helper to fix URLs ===\n",
    "def fix_url(url):\n",
    "    url = str(url).strip()\n",
    "    if not url.startswith((\"http://\", \"https://\")):\n",
    "        url = \"https://\" + url\n",
    "    return url\n",
    "\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "urls = df[\"news_url\"].dropna().head(NUM_ARTICLES).apply(fix_url)\n",
    "\n",
    "\n",
    "def fetch_article(idx, url):\n",
    "    \"\"\"Download + parse an article safely with timeout.\"\"\"\n",
    "    try:\n",
    "        # quick HEAD check so we don’t waste time on dead links\n",
    "        r = requests.head(url, timeout=5)\n",
    "        if r.status_code >= 400:\n",
    "            return None\n",
    "\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text = article.text.strip()\n",
    "        if not text:\n",
    "            return None\n",
    "\n",
    "        return {\"id\": idx, \"url\": url, \"title\": article.title, \"text\": text}\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "results = []\n",
    "start = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(fetch_article, idx, url): (idx, url) for idx, url in enumerate(urls, start=1)}\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        idx, url = futures[future]\n",
    "        try:\n",
    "            result = future.result(timeout=TIMEOUT)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "                print(f\"✅ [{idx}] Success: {url}\")\n",
    "            else:\n",
    "                print(f\"⚠️ [{idx}] Empty/failed: {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ [{idx}] Error: {url} ({e})\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# === Save results ===\n",
    "out_df = pd.DataFrame(results)\n",
    "out_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"\\n✅ Done! Scraped {len(out_df)} / {NUM_ARTICLES} successfully.\")\n",
    "print(f\"Saved to {OUTPUT_FILE}\")\n",
    "print(f\"⏱️ Took {end - start:.2f} seconds total\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60159abb",
   "metadata": {},
   "source": [
    "for 8 workers, 5 timeout, 169.22 seconds for 266 / 500 processed successfully.\n",
    "* Predicted: 24,000 article entries out of 45,000 total from ISOT in around 4 hours.\n",
    "\n",
    "for 4 workers 5 timeout, 267 / 500, took 241.78\n",
    "\n",
    "for 16 workers 10 timeout, 265/500, 139.10\n",
    "\n",
    "seems like timeout isn't making a huge difference within the 5-10 margin, but adding workers does improve time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
